@inproceedings{opauc,
    title={One-Pass AUC Optimization},
    author={Wei Gao and Lu Wang and Rong Jin and Shenghuo Zhu and Zhi-Hua Zhou},
    booktitle={Artificial Intelligence Journal},
    year={2016},
    volume={236},
    pages={1-29},
}
@inproceedings{beygelzimer2015optimal,
  title={Optimal and Adaptive Algorithms for Online Boosting},
  author={Beygelzimer, Alina and Kale, Satyen and Luo, Haipeng},
  booktitle={ICML},
  pages={2323--2331},
  year={2015}
}

@inproceedings{grubb2011generalized,
  title={Generalized Boosting Algorithms for Convex Optimization},
  author={Grubb, Alexander and Bagnell, Drew},
  booktitle={ICML},
  year={2011}
}

@book{schapire2012boosting,
  title={Boosting: Foundations and algorithms},
  author={Schapire, Robert E and Freund, Yoav},
  year={2012},
  publisher={MIT press}
}


@article{Shwartz2011_FTML,
author = {Shalev-Shwartz, Shai},
journal = {Foundations and Trends® in Machine Learning},
number = {2},
pages = {107--194},
title = {{Online Learning and Online Convex Optimization}},
volume = {4},
year = {2011}
}

@article{friedman2001greedy,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}

@inproceedings{beygelzimer2015online,
  title={Online Gradient Boosting},
  author={Beygelzimer, Alina and Hazan, Elad and Kale, Satyen and Luo, Haipeng},
  booktitle={NIPS},
  pages={2449--2457},
  year={2015}
}

@inproceedings{bengio2005convex,
  title={Convex neural networks},
  author={Bengio, Yoshua and Roux, Nicolas L and Vincent, Pascal and Delalleau, Olivier and Marcotte, Patrice},
  booktitle={NIPS},
  pages={123--130},
  year={2005}
}

@inproceedings{grubb2012speedboost,
  title={Speedboost: Anytime prediction with uniform near-optimality},
  author={Grubb, Alexander and Bagnell, Drew},
  booktitle={AISTATS},
  pages={458--466},
  year={2012}
}

% gradient boost as gradient descent 
@INPROCEEDINGS{Mason00boostingalgorithms,
    author = {Llew Mason and Jonathan Baxter and Peter Bartlett and Marcus Frean},
    title = {Boosting Algorithms as Gradient Descent},
    booktitle = {NIPS},
    year = {2000},
}


%%%%% Why Boosting is good!
@proceedings{yahoo,
  editor    = {Olivier Chapelle and
               Yi Chang and
               Tie{-}Yan Liu},
  title     = {Proceedings of the Yahoo! Learning to Rank Challenge, held at {ICML}
               2010},
  series    = {{JMLR} Proceedings},
  volume    = {14},
  year      = {2011},
}

@inproceedings{nam2014local,
  title={Local decorrelation for improved pedestrian detection},
  author={Nam, Woonhyun and Doll{\'a}r, Piotr and Han, Joon Hee},
  booktitle={NIPS},
  pages={424--432},
  year={2014}
}

@inproceedings{yang2015convolutional,
  title={Convolutional channel features},
  author={Yang, Bin and Yan, Junjie and Lei, Zhen and Li, Stan Z},
  booktitle={ICCV},
  pages={82--90},
  year={2015}
}

@inproceedings{zhu2016,
	author = {Chao Zhu and Yuxin Peng},
	title = {Group Cost-Sensitive Boosting for Multi-Resolution Pedestrian Detection},
	booktitle = {AAAI},
	year = {2016}
}

@inproceedings{viola2001rapid,
  title={Rapid object detection using a boosted cascade of simple features},
  author={Viola, Paul and Jones, Michael},
  booktitle={CVPR},
  volume={1},
  year={2001},
  organization={IEEE}
}

@article{atkinson2012assessing,
  title={Assessing fracture risk using gradient boosting machine (GBM) models},
  author={Atkinson, Elizabeth J and Therneau, Terry M and Melton, L Joseph and Camp, Jon J and Achenbach, Sara J and Amin, Shreyasee and Khosla, Sundeep},
  journal={Journal of Bone and Mineral Research},
  year={2012},
  publisher={Wiley Online Library}
}

@article{zhang2015gradient,
  title={A gradient boosting method to improve travel time prediction},
  author={Zhang, Yanru and Haghani, Ali},
  journal={Transportation Research Part C: Emerging Technologies},
  volume={58},
  pages={308--324},
  year={2015},
  publisher={Elsevier}
}

@article{zhang:2005,
title = {BOOSTING WITH EARLY STOPPING: CONVERGENCE AND CONSISTENCY},
author = {Tong Zhang and Bin Yu},
booktitle = {The Annals of Statistics},
year = {2005}, 
volume = {33},  
pages = {1538–1579}
}

@book{conv_opt,
title = {Convex Optimization},
author = {Boyd, S. and Vandenberghe, L.},
publisher = {Cambridge University Press, New York, NY, USA},
year = {2004},
}


% Online bagging and boosting via sample ~ poisson 
% extend bagging and adaboost
@INPROCEEDINGS{Oza01onlinebagging,
    author = {Nikunj C. Oza and Stuart Russell},
    title = {Online Bagging and Boosting},
    booktitle = {AISTATS},
    year = {2001},
    pages = {105--112}
}

% adopts oza (above) and select features (weak learners)
% apply to vision (detection/tracking)
@INPROCEEDINGS{grabner:2006,
    author = {H. Grabner and H. Bischof},
    title = {On-line boosting and vision},
    booktitle = {CVPR},
    year = {2006}, 
    volume = {1},
    pages = {260-267}
}

% Apply online boosting (above) for feat select to tracking.
@INPROCEEDINGS{grabner:2008,
author = {Grabner, H. and Leistner, C. and Bischof, H}, 
title = { Semisupervised on-line boosting for robust tracking},
booktitle = {ECCV}, 
pages ={234 – 247}, 
year = {2008}
}

% Online boosting via FTL on K weak learners, which are 
% trained using weighted samples. Sample weights are gradients magnitude.
@INPROCEEDINGS{leistner:2009,
author = {Leistner, C. and  Saffari, A. and Roth, P. M. and Bischof, H},
title = {On Robustness of On-line Boosting - A Competitive Study}, 
booktitle = {ICCV Workshop on On-line Learning for Computer Vision}, 
year = {2009}
}


% Update feature parameters using (backprop/gradient descent)
% online
@INPROCEEDINGS{yu:2007,
author ={ Xiaoming Liu and Ting Yu},
title = {Gradient feature selection for online boosting},
booktitle = {ICCV}, 
year = {2007}
}

% Assume weak learner edge, classification, smoothboost
@INPROCEEDINGS{lu:2012,
author = {Shang-Tse Chen and  Hsuan-Tien Lin and Chi-Jen Lu},
title = {An Online Boosting Algorithm with Theoretical Justifications},
booktitle = {ICML}, 
year = {2012}
}

% Multiclass prediction bandit setting. 
@INPROCEEDINGS{lu:2014,
author = {Shang-Tse Chen and Hsuan-Tien Lin and Chi-Jen Lu},
title = {Boosting with Online Binary Learners for the Multiclass Bandit Problem}, 
booktitle = {ICML}, 
year = {2014}
}

@article{hazan2007logarithmic,
  title={Logarithmic regret algorithms for online convex optimization},
  author={Hazan, Elad and Agarwal, Amit and Kale, Satyen},
  journal={Machine Learning},
  volume={69},
  number={2-3},
  pages={169--192},
  year={2007},
  publisher={Springer}
}

% Dataset Citations
@misc{slice,
  author = {F. Graf, H.-P. Kriegel, M. Schubert, S. Poelsterl, A. Cavallaro},
  title = {Relative location of CT slices on axial axis Data Set},
  howpublished= {UCI Machine Learning Repository},
  year={2011}
}
@misc{adult,
  author = {Ronny Kohavi and Barry Becker},
  title = {Adult Data Set},
  howpublished = {UCI Machine Learning Repository},
  year={1996}
}

@article{MNIST,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  year={1998},
  publisher={IEEE}
}


@misc{tensorflow,
    author = {et al., Abadi Mart\'{\i}  },
    institution = {Google Research},
    keywords = {distributed-system, machine-learning},
    title = {{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems (Preliminary White Paper, November 9, 2015)}},
    year = {2015}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={NIPS},
  pages={1097--1105},
  year={2012}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik and Ba, Jimmy},
  journal={ICLR, arXiv:1412.6980},
  year={2015}
}

@article{shalev2011online,
  title={Online learning and online convex optimization},
  author={Shalev-Shwartz, Shai},
  journal={Foundations and Trends in Machine Learning},
  volume={4},
  number={2},
  pages={107--194},
  year={2011}
}

@article{frank1956algorithm,
  title={An algorithm for quadratic programming},
  author={Frank, Marguerite and Wolfe, Philip},
  journal={Naval research logistics quarterly},
  volume={3},
  number={1-2},
  pages={95--110},
  year={1956},
  publisher={Wiley Online Library}
}

@article{JMLR:v15:hazan14a,
  author  = {Elad Hazan and Satyen Kale},
  title   = {Beyond the Regret Minimization Barrier: Optimal Algorithms for Stochastic Strongly-Convex Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  pages   = {2489-2512},
}

@article{cesa2004generalization,
  title={On the generalization ability of on-line learning algorithms},
  author={Cesa-Bianchi, Nicolo and Conconi, Alex and Gentile, Claudio},
  journal={IEEE Transactions on Information Theory},
  volume={50},
  number={9},
  pages={2050--2057},
  year={2004},
  publisher={IEEE}
}

@inproceedings{freund1995desicion,
  title={A desicion-theoretic generalization of on-line learning and an application to boosting},
  author={Freund, Yoav and Schapire, Robert E},
  booktitle={European conference on computational learning theory},
  pages={23--37},
  year={1995},
  organization={Springer}
}

@inproceedings{freund1999intro2boost,
 title={A Short Introduction to Boosting},
 author={Freund, Yoav and Schapire, Robert E},
 booktitle={Journal of Japanese Society for Artificial Intelligence},
 year={1999},
}

@misc{Lichman:2013 ,
author = "M. Lichman",
year = "2013",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@inproceedings{SVRG,
title = {Accelerating Stochastic Gradient Descent using Predictive Variance Reduction},
author = {Johnson, Rie and Zhang, Tong},
booktitle = {Advances in Neural Information Processing Systems 26},
year = {2013},
}
